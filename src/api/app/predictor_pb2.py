# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: predictor.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0fpredictor.proto\"\x18\n\x07Request\x12\r\n\x05input\x18\x01 \x01(\t\"\x1b\n\nPrediction\x12\r\n\x05value\x18\x01 \x01(\t\"h\n\x08Metadata\x12\x14\n\x0cmodelVersion\x18\x01 \x01(\t\x12\x11\n\tmodelHash\x18\x02 \x01(\t\x12\x11\n\tmodelName\x18\x03 \x01(\t\x12 \n\x18serviceCreationTimestamp\x18\x04 \x01(\t\"c\n\x08Response\x12\x0e\n\x06status\x18\x01 \x01(\t\x12\x0f\n\x07message\x18\x02 \x01(\t\x12\x1b\n\x08metadata\x18\x03 \x03(\x0b\x32\t.Metadata\x12\x19\n\x04\x64\x61ta\x18\x04 \x01(\x0b\x32\x0b.Prediction2?\n\x13LargeModelPredictor\x12(\n\x0fget_predictions\x12\x08.Request\x1a\t.Response\"\x00\x62\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'predictor_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  _REQUEST._serialized_start=19
  _REQUEST._serialized_end=43
  _PREDICTION._serialized_start=45
  _PREDICTION._serialized_end=72
  _METADATA._serialized_start=74
  _METADATA._serialized_end=178
  _RESPONSE._serialized_start=180
  _RESPONSE._serialized_end=279
  _LARGEMODELPREDICTOR._serialized_start=281
  _LARGEMODELPREDICTOR._serialized_end=344
# @@protoc_insertion_point(module_scope)
